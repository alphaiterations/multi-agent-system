{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc52517",
   "metadata": {},
   "source": [
    "## Installing Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522f7b98",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "355bfdd2",
   "metadata": {},
   "source": [
    "## Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f0de4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vijendra/multi-agent-system/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Load environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPEN_AI_KEY\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89cc5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"deccan-ai/insuranceQA-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9afa1",
   "metadata": {},
   "source": [
    "### Setting up the FAQ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f6b838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What Does Medicare IME Stand For?</td>\n",
       "      <td>According to the Centers for Medicare and Medi...</td>\n",
       "      <td>Question: What Does Medicare IME Stand For?  \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Long Term Care Insurance Tax Free?</td>\n",
       "      <td>As a rule , if you buy a tax qualified long te...</td>\n",
       "      <td>Question: Is Long Term Care Insurance Tax Free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can Husband Drop Wife From Health Insurance?</td>\n",
       "      <td>Can a spouse drop another spouse from health i...</td>\n",
       "      <td>Question: Can Husband Drop Wife From Health In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is Medicare Run By The Government?</td>\n",
       "      <td>Medicare Part A and Part B is provided by the ...</td>\n",
       "      <td>Question: Is Medicare Run By The Government?  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is Medicare Run By The Government?</td>\n",
       "      <td>Definitely . It is ran by the Center for Medic...</td>\n",
       "      <td>Question: Is Medicare Run By The Government?  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input  \\\n",
       "0             What Does Medicare IME Stand For?    \n",
       "1         Is Long Term Care Insurance Tax Free?    \n",
       "2  Can Husband Drop Wife From Health Insurance?    \n",
       "3            Is Medicare Run By The Government?    \n",
       "4            Is Medicare Run By The Government?    \n",
       "\n",
       "                                              output  \\\n",
       "0  According to the Centers for Medicare and Medi...   \n",
       "1  As a rule , if you buy a tax qualified long te...   \n",
       "2  Can a spouse drop another spouse from health i...   \n",
       "3  Medicare Part A and Part B is provided by the ...   \n",
       "4  Definitely . It is ran by the Center for Medic...   \n",
       "\n",
       "                                            combined  \n",
       "0  Question: What Does Medicare IME Stand For?  \\...  \n",
       "1  Question: Is Long Term Care Insurance Tax Free...  \n",
       "2  Question: Can Husband Drop Wife From Health In...  \n",
       "3  Question: Is Medicare Run By The Government?  ...  \n",
       "4  Question: Is Medicare Run By The Government?  ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "ds = load_dataset(\"deccan-ai/insuranceQA-v2\")\n",
    "\n",
    "# Combine all splits into a single DataFrame\n",
    "df = pd.concat([split.to_pandas() for split in ds.values()], ignore_index=True)\n",
    "df[\"combined\"] = \"Question: \" + df[\"input\"] + \" \\n Answer:  \" + df[\"output\"]\n",
    "# Inspect\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9cd8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "# Setting up the Chromadb\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dffdc953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# Collection 1 for insurance Q&A Dataset\n",
    "from tqdm import tqdm\n",
    "df = df.sample(200, random_state=42).reset_index(drop=True)  # For testing, use a smaller subset\n",
    "collection = client.get_or_create_collection(name=\"insurance_FAQ_collection\")\n",
    "# Add data to collection\n",
    "# here the chroma db will use default embeddings (sentence transformers)\n",
    "# Split into batches of <= 5000\n",
    "batch_size = 100\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    batch_df = df.iloc[i:i+batch_size]\n",
    "    collection.add(\n",
    "        documents=batch_df[\"combined\"].tolist(),\n",
    "        metadatas=[{\"question\": q, \"answer\": a} for q, a in zip(batch_df[\"input\"], batch_df[\"output\"])],\n",
    "        ids=batch_df.index.astype(str).tolist()\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9fade5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['18546', '18549', '1283']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Question: What Does Life Insurance Typically Cover?  \\n Answer:  Life insurance is intended to provide some monetary assistance in the event that the insured passes away while covered . Life insurance is typically meant as a way for the family of the insured to be financially capable of moving on after the loss . The funds from the policy are intended to help provide for those things that could have possibly been provided -LRB- i.e. pay off debt , pay for college , etc. . . -RRB- by the insured if the insured had not passed . This is a very limited explanation of life insurance , contact a local agent to discuss your wants and needs with this type of coverage . ',\n",
       "   'Question: What Does Life Insurance Typically Cover?  \\n Answer:  Life insurance is designed to pay a determined benefit amount upon the death of the insured . Any cause of death is typically covered except suicide within the first two years of the policy . If it can be proved that fraud was committed in obtaining the policy then only the amount of premiums paid will be returned to the beneficiary . ',\n",
       "   'Question: What Does Life Insurance Not Cover?  \\n Answer:  The only thing that all life insurance policies do not cover is death due to suicide in the first two years of the policy . Some policies will exclude death caused during the commission of a crime , or by acts of war or terrorism . Others could have a stipulation , such as death caused by parachuting , but that will be an exception stated explicitly in your policy for your particular situation . Life insurance pays for death due to old age , anything health related , and accident . This covers the vast majority of causes of death . ']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'answer': 'Life insurance is intended to provide some monetary assistance in the event that the insured passes away while covered . Life insurance is typically meant as a way for the family of the insured to be financially capable of moving on after the loss . The funds from the policy are intended to help provide for those things that could have possibly been provided -LRB- i.e. pay off debt , pay for college , etc. . . -RRB- by the insured if the insured had not passed . This is a very limited explanation of life insurance , contact a local agent to discuss your wants and needs with this type of coverage . ',\n",
       "    'question': 'What Does Life Insurance Typically Cover? '},\n",
       "   {'answer': 'Life insurance is designed to pay a determined benefit amount upon the death of the insured . Any cause of death is typically covered except suicide within the first two years of the policy . If it can be proved that fraud was committed in obtaining the policy then only the amount of premiums paid will be returned to the beneficiary . ',\n",
       "    'question': 'What Does Life Insurance Typically Cover? '},\n",
       "   {'answer': 'The only thing that all life insurance policies do not cover is death due to suicide in the first two years of the policy . Some policies will exclude death caused during the commission of a crime , or by acts of war or terrorism . Others could have a stipulation , such as death caused by parachuting , but that will be an exception stated explicitly in your policy for your particular situation . Life insurance pays for death due to old age , anything health related , and accident . This covers the vast majority of causes of death . ',\n",
       "    'question': 'What Does Life Insurance Not Cover? '}]],\n",
       " 'distances': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96bfcc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1:\n",
      "Q: What Does Life Insurance Typically Cover? \n",
      "A: Life insurance is intended to provide some monetary assistance in the event that the insured passes away while covered . Life insurance is typically meant as a way for the family of the insured to be financially capable of moving on after the loss . The funds from the policy are intended to help provide for those things that could have possibly been provided -LRB- i.e. pay off debt , pay for college , etc. . . -RRB- by the insured if the insured had not passed . This is a very limited explanation of life insurance , contact a local agent to discuss your wants and needs with this type of coverage . \n",
      "--------------------------------------------------\n",
      "Result 2:\n",
      "Q: What Does Life Insurance Typically Cover? \n",
      "A: Life insurance is designed to pay a determined benefit amount upon the death of the insured . Any cause of death is typically covered except suicide within the first two years of the policy . If it can be proved that fraud was committed in obtaining the policy then only the amount of premiums paid will be returned to the beneficiary . \n",
      "--------------------------------------------------\n",
      "Result 3:\n",
      "Q: What Does Life Insurance Not Cover? \n",
      "A: The only thing that all life insurance policies do not cover is death due to suicide in the first two years of the policy . Some policies will exclude death caused during the commission of a crime , or by acts of war or terrorism . Others could have a stipulation , such as death caused by parachuting , but that will be an exception stated explicitly in your policy for your particular situation . Life insurance pays for death due to old age , anything health related , and accident . This covers the vast majority of causes of death . \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Testing the retrieval\n",
    "query = \"What does life insurance cover?\"\n",
    "collection = client.get_collection(name=\"insurance_FAQ_collection\")\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=3,\n",
    "    include=[\"metadatas\", \"documents\"]\n",
    ")\n",
    "\n",
    "for i, m in enumerate(results[\"metadatas\"][0]):\n",
    "    print(f\"Result {i+1}:\")\n",
    "    #print(\"Score:\", results[\"distances\"][0][i])\n",
    "    print(\"Q:\", m[\"question\"])\n",
    "    print(\"A:\", m[\"answer\"])\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993f288",
   "metadata": {},
   "source": [
    "## Generating Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5614da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "def generate_sample_data():\n",
    "    \"\"\"Generate enriched sample data for all tables with 50 first/last names\"\"\"\n",
    "    # Define 50 first and last names\n",
    "    first_names = [\n",
    "        \"John\", \"Jane\", \"Robert\", \"Maria\", \"David\", \"Lisa\", \"Michael\", \"Sarah\", \"James\", \"Emily\",\n",
    "        \"William\", \"Emma\", \"Joseph\", \"Olivia\", \"Charles\", \"Ava\", \"Thomas\", \"Isabella\", \"Daniel\", \"Mia\",\n",
    "        \"Matthew\", \"Sophia\", \"Anthony\", \"Charlotte\", \"Christopher\", \"Amelia\", \"Andrew\", \"Harper\",\n",
    "        \"Joshua\", \"Evelyn\", \"Ryan\", \"Abigail\", \"Brandon\", \"Ella\", \"Justin\", \"Scarlett\", \"Tyler\", \"Grace\",\n",
    "        \"Alexander\", \"Chloe\", \"Kevin\", \"Victoria\", \"Jason\", \"Lily\", \"Brian\", \"Hannah\", \"Eric\", \"Aria\",\n",
    "        \"Kyle\", \"Zoey\"\n",
    "    ]\n",
    "\n",
    "    last_names = [\n",
    "        \"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\", \"Rodriguez\", \"Martinez\",\n",
    "        \"Hernandez\", \"Lopez\", \"Gonzalez\", \"Wilson\", \"Anderson\", \"Thomas\", \"Taylor\", \"Moore\", \"Jackson\", \"Martin\",\n",
    "        \"Lee\", \"Perez\", \"Thompson\", \"White\", \"Harris\", \"Sanchez\", \"Clark\", \"Ramirez\", \"Lewis\", \"Robinson\",\n",
    "        \"Walker\", \"Young\", \"Allen\", \"King\", \"Wright\", \"Scott\", \"Torres\", \"Nguyen\", \"Hill\", \"Flores\",\n",
    "        \"Green\", \"Adams\", \"Nelson\", \"Baker\", \"Hall\", \"Rivera\", \"Campbell\", \"Mitchell\", \"Carter\", \"Roberts\"\n",
    "    ]\n",
    "\n",
    "    # Generate customers (1000 random name combinations)\n",
    "    customers = pd.DataFrame({\n",
    "        'customer_id': [f'CUST{str(i).zfill(5)}' for i in range(1, 1001)],\n",
    "        'first_name': [random.choice(first_names) for _ in range(1000)],\n",
    "        'last_name': [random.choice(last_names) for _ in range(1000)],\n",
    "        'email': [f'user{i}@example.com' for i in range(1, 1001)],\n",
    "        'phone': [f'555-{str(random.randint(100,999)).zfill(3)}-{str(random.randint(1000,9999)).zfill(4)}' for _ in range(1000)],\n",
    "        'date_of_birth': [datetime(1980, 1, 1) + timedelta(days=random.randint(0, 10000)) for _ in range(1000)],\n",
    "        'state': [random.choice(['CA', 'NY', 'TX', 'FL', 'IL', 'PA', 'OH', 'GA']) for _ in range(1000)]\n",
    "    })\n",
    "\n",
    "    # Policies\n",
    "    policies = pd.DataFrame({\n",
    "        'policy_number': [f'POL{str(i).zfill(6)}' for i in range(1, 1501)],\n",
    "        'customer_id': [f'CUST{str(random.randint(1, 1000)).zfill(5)}' for _ in range(1500)],\n",
    "        'policy_type': [random.choice(['auto', 'home', 'life']) for _ in range(1500)],\n",
    "        'start_date': [datetime(2023, 1, 1) + timedelta(days=random.randint(0, 365)) for _ in range(1500)],\n",
    "        'premium_amount': [round(random.uniform(50, 500), 2) for _ in range(1500)],\n",
    "        'billing_frequency': [random.choice(['monthly', 'quarterly', 'annual']) for _ in range(1500)],\n",
    "        'status': [random.choice(['active', 'active', 'active', 'cancelled']) for _ in range(1500)]\n",
    "    })\n",
    "\n",
    "    # Auto Policy Details (subset)\n",
    "    auto_policies = policies[policies['policy_type'] == 'auto'].copy()\n",
    "    auto_policy_details = pd.DataFrame({\n",
    "        'policy_number': auto_policies['policy_number'],\n",
    "        'vehicle_vin': [f'VIN{random.randint(10000000000000000, 99999999999999999)}' for _ in range(len(auto_policies))],\n",
    "        'vehicle_make': [random.choice(['Toyota', 'Honda', 'Ford', 'Chevrolet', 'Nissan']) for _ in range(len(auto_policies))],\n",
    "        'vehicle_model': [random.choice(['Camry', 'Civic', 'F-150', 'Malibu', 'Altima']) for _ in range(len(auto_policies))],\n",
    "        'vehicle_year': [random.randint(2015, 2023) for _ in range(len(auto_policies))],\n",
    "        'liability_limit': [random.choice([50000, 100000, 300000]) for _ in range(len(auto_policies))],\n",
    "        'collision_deductible': [random.choice([250, 500, 1000]) for _ in range(len(auto_policies))],\n",
    "        'comprehensive_deductible': [random.choice([250, 500, 1000]) for _ in range(len(auto_policies))],\n",
    "        'uninsured_motorist': [random.choice([0, 1]) for _ in range(len(auto_policies))],\n",
    "        'rental_car_coverage': [random.choice([0, 1]) for _ in range(len(auto_policies))]\n",
    "    })\n",
    "\n",
    "    # Payment Methods\n",
    "    payment_methods = pd.DataFrame({\n",
    "        'method_id': [f'PM{str(i).zfill(6)}' for i in range(1, 1501)],\n",
    "        'customer_id': [f'CUST{str(random.randint(1, 1000)).zfill(5)}' for _ in range(1500)],\n",
    "        'payment_type': [random.choice(['credit_card', 'debit_card', 'bank_account']) for _ in range(1500)],\n",
    "        'last_four_digits': [f'{random.randint(1000,9999)}' for _ in range(1500)],\n",
    "        'expiry_date': [f'202{random.randint(5,8)}-{random.randint(1,12):02d}-{random.randint(1,28):02d}' for _ in range(1500)],\n",
    "        'is_default': [random.choice([0, 1]) for _ in range(1500)]\n",
    "    })\n",
    "\n",
    "    # Billing\n",
    "    billing = pd.DataFrame({\n",
    "        'bill_id': [f'BILL{str(i).zfill(6)}' for i in range(1, 5001)],\n",
    "        'policy_number': [random.choice(policies['policy_number']) for _ in range(5000)],\n",
    "        'billing_date': [datetime(2024, 1, 1) + timedelta(days=random.randint(0, 90)) for _ in range(5000)],\n",
    "        'due_date': [datetime(2024, 1, 15) + timedelta(days=random.randint(0, 90)) for _ in range(5000)],\n",
    "        'amount_due': [round(random.uniform(100, 1000), 2) for _ in range(5000)],\n",
    "        'status': [random.choice(['paid', 'pending', 'overdue']) for _ in range(5000)]\n",
    "    })\n",
    "\n",
    "    # Payments\n",
    "    payments = pd.DataFrame({\n",
    "        'payment_id': [f'PAY{str(i).zfill(6)}' for i in range(1, 4001)],\n",
    "        'bill_id': [random.choice(billing['bill_id']) for _ in range(4000)],\n",
    "        'payment_date': [datetime(2024, 1, 1) + timedelta(days=random.randint(0, 90)) for _ in range(4000)],\n",
    "        'amount': [round(random.uniform(50, 500), 2) for _ in range(4000)],\n",
    "        'payment_method': [random.choice(['credit_card', 'debit_card', 'bank_transfer']) for _ in range(4000)],\n",
    "        'transaction_id': [f'TXN{random.randint(100000,999999)}' for _ in range(4000)],\n",
    "        'status': [random.choice(['completed', 'pending', 'failed']) for _ in range(4000)]\n",
    "    })\n",
    "\n",
    "    # Claims\n",
    "    claims = pd.DataFrame({\n",
    "        'claim_id': [f'CLM{str(i).zfill(6)}' for i in range(1, 301)],\n",
    "        'policy_number': [random.choice(policies['policy_number']) for _ in range(300)],\n",
    "        'claim_date': [datetime(2024, 1, 1) + timedelta(days=random.randint(0, 90)) for _ in range(300)],\n",
    "        'incident_type': [random.choice(['collision', 'theft', 'property_damage', 'medical', 'liability']) for _ in range(300)],\n",
    "        'estimated_loss': [round(random.uniform(500, 20000), 2) for _ in range(300)],\n",
    "        'status': [random.choice(['submitted', 'under_review', 'approved', 'paid', 'denied']) for _ in range(300)]\n",
    "    })\n",
    "\n",
    "    # Claim Documents\n",
    "    claim_documents = pd.DataFrame({\n",
    "        'document_id': [f'DOC{str(i).zfill(6)}' for i in range(1, 601)],\n",
    "        'claim_id': [random.choice(claims['claim_id']) for _ in range(600)],\n",
    "        'document_type': [random.choice(['photo', 'police_report', 'estimate', 'invoice']) for _ in range(600)],\n",
    "        'document_url': [f'https://example.com/documents/{i}.pdf' for i in range(1, 601)],\n",
    "        'uploaded_date': [datetime.now() - timedelta(days=random.randint(0, 60)) for _ in range(600)]\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        'customers': customers,\n",
    "        'policies': policies,\n",
    "        'auto_policy_details': auto_policy_details,\n",
    "        'payment_methods': payment_methods,\n",
    "        'billing': billing,\n",
    "        'payments': payments,\n",
    "        'claims': claims,\n",
    "        'claim_documents': claim_documents\n",
    "    }\n",
    "\n",
    "\n",
    "sample_data = generate_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee8bfe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custimers Data Shape: (1000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUST00001</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Ramirez</td>\n",
       "      <td>user1@example.com</td>\n",
       "      <td>555-197-4851</td>\n",
       "      <td>1990-06-13</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUST00002</td>\n",
       "      <td>Amelia</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>user2@example.com</td>\n",
       "      <td>555-909-6882</td>\n",
       "      <td>1996-06-06</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUST00003</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>Jones</td>\n",
       "      <td>user3@example.com</td>\n",
       "      <td>555-472-9099</td>\n",
       "      <td>2006-06-28</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUST00004</td>\n",
       "      <td>Scarlett</td>\n",
       "      <td>Robinson</td>\n",
       "      <td>user4@example.com</td>\n",
       "      <td>555-848-5031</td>\n",
       "      <td>2003-04-15</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUST00005</td>\n",
       "      <td>James</td>\n",
       "      <td>Flores</td>\n",
       "      <td>user5@example.com</td>\n",
       "      <td>555-879-2450</td>\n",
       "      <td>2002-06-29</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id   first_name last_name              email         phone  \\\n",
       "0   CUST00001  Christopher   Ramirez  user1@example.com  555-197-4851   \n",
       "1   CUST00002       Amelia    Thomas  user2@example.com  555-909-6882   \n",
       "2   CUST00003        Kevin     Jones  user3@example.com  555-472-9099   \n",
       "3   CUST00004     Scarlett  Robinson  user4@example.com  555-848-5031   \n",
       "4   CUST00005        James    Flores  user5@example.com  555-879-2450   \n",
       "\n",
       "  date_of_birth state  \n",
       "0    1990-06-13    OH  \n",
       "1    1996-06-06    IL  \n",
       "2    2006-06-28    IL  \n",
       "3    2003-04-15    IL  \n",
       "4    2002-06-29    GA  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Custimers Data Shape:\", sample_data[\"customers\"].shape)\n",
    "sample_data[\"customers\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca22bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "billing Data Shape: (5000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_id</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>billing_date</th>\n",
       "      <th>due_date</th>\n",
       "      <th>amount_due</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BILL000001</td>\n",
       "      <td>POL000610</td>\n",
       "      <td>2024-02-13</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>947.85</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BILL000002</td>\n",
       "      <td>POL000334</td>\n",
       "      <td>2024-02-23</td>\n",
       "      <td>2024-02-25</td>\n",
       "      <td>203.10</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BILL000003</td>\n",
       "      <td>POL000010</td>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>2024-03-25</td>\n",
       "      <td>652.12</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BILL000004</td>\n",
       "      <td>POL001122</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>2024-01-19</td>\n",
       "      <td>858.38</td>\n",
       "      <td>pending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BILL000005</td>\n",
       "      <td>POL001227</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>2024-03-05</td>\n",
       "      <td>593.06</td>\n",
       "      <td>overdue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bill_id policy_number billing_date   due_date  amount_due   status\n",
       "0  BILL000001     POL000610   2024-02-13 2024-03-31      947.85  pending\n",
       "1  BILL000002     POL000334   2024-02-23 2024-02-25      203.10     paid\n",
       "2  BILL000003     POL000010   2024-02-01 2024-03-25      652.12  pending\n",
       "3  BILL000004     POL001122   2024-01-04 2024-01-19      858.38  pending\n",
       "4  BILL000005     POL001227   2024-02-28 2024-03-05      593.06  overdue"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"billing Data Shape:\", sample_data[\"billing\"].shape)\n",
    "sample_data[\"billing\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eb6240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claims Data Shape: (300, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>claim_date</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>estimated_loss</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLM000001</td>\n",
       "      <td>POL001200</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>collision</td>\n",
       "      <td>19442.86</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLM000002</td>\n",
       "      <td>POL001293</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>theft</td>\n",
       "      <td>8772.50</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLM000003</td>\n",
       "      <td>POL001150</td>\n",
       "      <td>2024-02-02</td>\n",
       "      <td>property_damage</td>\n",
       "      <td>9072.73</td>\n",
       "      <td>denied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLM000004</td>\n",
       "      <td>POL000126</td>\n",
       "      <td>2024-01-26</td>\n",
       "      <td>liability</td>\n",
       "      <td>10129.98</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CLM000005</td>\n",
       "      <td>POL000444</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>medical</td>\n",
       "      <td>14822.64</td>\n",
       "      <td>approved</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    claim_id policy_number claim_date    incident_type  estimated_loss  \\\n",
       "0  CLM000001     POL001200 2024-02-26        collision        19442.86   \n",
       "1  CLM000002     POL001293 2024-02-28            theft         8772.50   \n",
       "2  CLM000003     POL001150 2024-02-02  property_damage         9072.73   \n",
       "3  CLM000004     POL000126 2024-01-26        liability        10129.98   \n",
       "4  CLM000005     POL000444 2024-03-01          medical        14822.64   \n",
       "\n",
       "     status  \n",
       "0      paid  \n",
       "1      paid  \n",
       "2    denied  \n",
       "3      paid  \n",
       "4  approved  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"claims Data Shape:\", sample_data[\"claims\"].shape)\n",
    "sample_data[\"claims\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d1a4049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies Data Shape: (1500, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_number</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>premium_amount</th>\n",
       "      <th>billing_frequency</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POL000001</td>\n",
       "      <td>CUST00757</td>\n",
       "      <td>home</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>436.16</td>\n",
       "      <td>annual</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POL000002</td>\n",
       "      <td>CUST00379</td>\n",
       "      <td>home</td>\n",
       "      <td>2023-10-24</td>\n",
       "      <td>102.44</td>\n",
       "      <td>monthly</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POL000003</td>\n",
       "      <td>CUST00840</td>\n",
       "      <td>life</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>132.05</td>\n",
       "      <td>annual</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POL000004</td>\n",
       "      <td>CUST00651</td>\n",
       "      <td>life</td>\n",
       "      <td>2023-09-11</td>\n",
       "      <td>105.00</td>\n",
       "      <td>annual</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POL000005</td>\n",
       "      <td>CUST00568</td>\n",
       "      <td>auto</td>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>68.09</td>\n",
       "      <td>annual</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  policy_number customer_id policy_type start_date  premium_amount  \\\n",
       "0     POL000001   CUST00757        home 2023-04-25          436.16   \n",
       "1     POL000002   CUST00379        home 2023-10-24          102.44   \n",
       "2     POL000003   CUST00840        life 2023-03-23          132.05   \n",
       "3     POL000004   CUST00651        life 2023-09-11          105.00   \n",
       "4     POL000005   CUST00568        auto 2023-04-20           68.09   \n",
       "\n",
       "  billing_frequency     status  \n",
       "0            annual  cancelled  \n",
       "1           monthly  cancelled  \n",
       "2            annual     active  \n",
       "3            annual     active  \n",
       "4            annual  cancelled  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"policies Data Shape:\", sample_data[\"policies\"].shape)\n",
    "sample_data[\"policies\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49253759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['customers', 'policies', 'auto_policy_details', 'payment_methods', 'billing', 'payments', 'claims', 'claim_documents'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "462e2a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policies Data Shape: (497, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_number</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>policy_type</th>\n",
       "      <th>start_date</th>\n",
       "      <th>premium_amount</th>\n",
       "      <th>billing_frequency</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POL000001</td>\n",
       "      <td>CUST00757</td>\n",
       "      <td>home</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>436.16</td>\n",
       "      <td>annual</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POL000002</td>\n",
       "      <td>CUST00379</td>\n",
       "      <td>home</td>\n",
       "      <td>2023-10-24</td>\n",
       "      <td>102.44</td>\n",
       "      <td>monthly</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POL000003</td>\n",
       "      <td>CUST00840</td>\n",
       "      <td>life</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>132.05</td>\n",
       "      <td>annual</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POL000004</td>\n",
       "      <td>CUST00651</td>\n",
       "      <td>life</td>\n",
       "      <td>2023-09-11</td>\n",
       "      <td>105.00</td>\n",
       "      <td>annual</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POL000005</td>\n",
       "      <td>CUST00568</td>\n",
       "      <td>auto</td>\n",
       "      <td>2023-04-20</td>\n",
       "      <td>68.09</td>\n",
       "      <td>annual</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  policy_number customer_id policy_type start_date  premium_amount  \\\n",
       "0     POL000001   CUST00757        home 2023-04-25          436.16   \n",
       "1     POL000002   CUST00379        home 2023-10-24          102.44   \n",
       "2     POL000003   CUST00840        life 2023-03-23          132.05   \n",
       "3     POL000004   CUST00651        life 2023-09-11          105.00   \n",
       "4     POL000005   CUST00568        auto 2023-04-20           68.09   \n",
       "\n",
       "  billing_frequency     status  \n",
       "0            annual  cancelled  \n",
       "1           monthly  cancelled  \n",
       "2            annual     active  \n",
       "3            annual     active  \n",
       "4            annual  cancelled  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"policies Data Shape:\", sample_data[\"auto_policy_details\"].shape)\n",
    "sample_data[\"policies\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe732f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import json\n",
    "\n",
    "\n",
    "def connect_db(db_path='insurance_support.db'):\n",
    "    \"\"\"Connect to SQLite database\"\"\"\n",
    "    return sqlite3.connect(db_path)\n",
    "\n",
    "\n",
    "def drop_and_create_tables(conn):\n",
    "    \"\"\"Drop existing tables and recreate the schema\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Drop tables if exist\n",
    "    cursor.executescript(\"\"\"\n",
    "        DROP TABLE IF EXISTS claim_documents;\n",
    "        DROP TABLE IF EXISTS claims;\n",
    "        DROP TABLE IF EXISTS payments;\n",
    "        DROP TABLE IF EXISTS billing;\n",
    "        DROP TABLE IF EXISTS payment_methods;\n",
    "        DROP TABLE IF EXISTS auto_policy_details;\n",
    "        DROP TABLE IF EXISTS policies;\n",
    "        DROP TABLE IF EXISTS customers;\n",
    "    \"\"\")\n",
    "\n",
    "    # Create tables\n",
    "    cursor.executescript(\"\"\"\n",
    "        CREATE TABLE customers (\n",
    "            customer_id VARCHAR(20) PRIMARY KEY,\n",
    "            first_name VARCHAR(50),\n",
    "            last_name VARCHAR(50),\n",
    "            email VARCHAR(100),\n",
    "            phone VARCHAR(20),\n",
    "            date_of_birth DATE,\n",
    "            state VARCHAR(20)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE policies (\n",
    "            policy_number VARCHAR(20) PRIMARY KEY,\n",
    "            customer_id VARCHAR(20),\n",
    "            policy_type VARCHAR(50),\n",
    "            start_date DATE,\n",
    "            premium_amount DECIMAL(10,2),\n",
    "            billing_frequency VARCHAR(20),\n",
    "            status VARCHAR(20),\n",
    "            FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE auto_policy_details (\n",
    "            policy_number VARCHAR(20) PRIMARY KEY,\n",
    "            vehicle_vin VARCHAR(50),\n",
    "            vehicle_make VARCHAR(50),\n",
    "            vehicle_model VARCHAR(50),\n",
    "            vehicle_year INTEGER,\n",
    "            liability_limit DECIMAL(10,2),\n",
    "            collision_deductible DECIMAL(10,2),\n",
    "            comprehensive_deductible DECIMAL(10,2),\n",
    "            uninsured_motorist BOOLEAN,\n",
    "            rental_car_coverage BOOLEAN,\n",
    "            FOREIGN KEY (policy_number) REFERENCES policies(policy_number)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE payment_methods (\n",
    "            method_id VARCHAR(20) PRIMARY KEY,\n",
    "            customer_id VARCHAR(20),\n",
    "            payment_type VARCHAR(50),\n",
    "            last_four_digits VARCHAR(4),\n",
    "            expiry_date DATE,\n",
    "            is_default BOOLEAN,\n",
    "            FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE billing (\n",
    "            bill_id VARCHAR(20) PRIMARY KEY,\n",
    "            policy_number VARCHAR(20),\n",
    "            billing_date DATE,\n",
    "            due_date DATE,\n",
    "            amount_due DECIMAL(10,2),\n",
    "            status VARCHAR(20),\n",
    "            FOREIGN KEY (policy_number) REFERENCES policies(policy_number)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE payments (\n",
    "            payment_id VARCHAR(20) PRIMARY KEY,\n",
    "            bill_id VARCHAR(20),\n",
    "            payment_date DATE,\n",
    "            amount DECIMAL(10,2),\n",
    "            payment_method VARCHAR(50),\n",
    "            transaction_id VARCHAR(100),\n",
    "            status VARCHAR(20),\n",
    "            FOREIGN KEY (bill_id) REFERENCES billing(bill_id)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE claims (\n",
    "            claim_id VARCHAR(20) PRIMARY KEY,\n",
    "            policy_number VARCHAR(20),\n",
    "            claim_date DATE,\n",
    "            incident_type VARCHAR(100),\n",
    "            estimated_loss DECIMAL(10,2),\n",
    "            status VARCHAR(20),\n",
    "            FOREIGN KEY (policy_number) REFERENCES policies(policy_number)\n",
    "        );\n",
    "\n",
    "        CREATE TABLE claim_documents (\n",
    "            document_id VARCHAR(20) PRIMARY KEY,\n",
    "            claim_id VARCHAR(20),\n",
    "            document_type VARCHAR(50),\n",
    "            document_url TEXT,\n",
    "            uploaded_date TIMESTAMP,\n",
    "            FOREIGN KEY (claim_id) REFERENCES claims(claim_id)\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b714bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database created successfully with enriched synthetic data!\n"
     ]
    }
   ],
   "source": [
    "def insert_data(conn, data):\n",
    "    \"\"\"Insert all DataFrames into SQLite\"\"\"\n",
    "    for table, df in data.items():\n",
    "        df.to_sql(table, conn, if_exists='append', index=False)\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def setup_insurance_database():\n",
    "    \"\"\"Main function to create and populate the insurance database\"\"\"\n",
    "    conn = connect_db()\n",
    "    drop_and_create_tables(conn)\n",
    "    data = generate_sample_data()\n",
    "    insert_data(conn, data)\n",
    "    conn.close()\n",
    "    print(\"✅ Database created successfully with enriched synthetic data!\")\n",
    "\n",
    "\n",
    "\n",
    "setup_insurance_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d1e70b",
   "metadata": {},
   "source": [
    "### Setting up Open AI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "089532db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relativity says measurements of space and time depend on motion. Special relativity fixes light speed and links space-time; general relativity describes gravity as mass and energy curving space-time, guiding motion.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "def llm_without_tool(prompt: str) -> str:\n",
    "    \"\"\"Function to get response from LLM\"\"\"\n",
    "    from openai import OpenAI\n",
    "    client_llm = OpenAI(api_key=openai_api_key)\n",
    "    response = client_llm.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## testing the LLM response\n",
    "prompt = \"Explain the theory of relativity in simple terms in 30 words\"\n",
    "response = llm_without_tool(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6b818b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "#  Define a helper for LLM + tool handling\n",
    "# =====================================================\n",
    "\n",
    "# --- Initialize OpenAI client ---\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "import json\n",
    "def run_llm_with_tools(prompt: str, tools: List[Dict], tool_functions: Dict[str, Any]):\n",
    "    # Step 1: Ask model with tool availability\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",  # Fixed model name\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "\n",
    "    # Step 2: If no tool calls, just return the model response\n",
    "    if not getattr(message, \"tool_calls\", None):\n",
    "        return message.content\n",
    "\n",
    "    # Step 3: Handle tool calls properly\n",
    "    tool_messages = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        func_name = tool_call.function.name\n",
    "        args = json.loads(tool_call.function.arguments or \"{}\")\n",
    "        tool_fn = tool_functions.get(func_name)\n",
    "\n",
    "        if not tool_fn:\n",
    "            result = {\"error\": f\"Tool function '{func_name}' not implemented.\"}\n",
    "        else:\n",
    "            try:\n",
    "                result = tool_fn(**args)\n",
    "            except Exception as e:\n",
    "                result = {\"error\": str(e)}\n",
    "\n",
    "        tool_messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"content\": json.dumps(result)\n",
    "        })\n",
    "\n",
    "    # Step 4: Follow-up completion with correct message chain\n",
    "    followup_messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message.content,\n",
    "            \"tool_calls\": [\n",
    "                {\n",
    "                    \"id\": tc.id,\n",
    "                    \"type\": tc.type,\n",
    "                    \"function\": {\n",
    "                        \"name\": tc.function.name,\n",
    "                        \"arguments\": tc.function.arguments,\n",
    "                    },\n",
    "                } for tc in message.tool_calls\n",
    "            ],\n",
    "        },\n",
    "        *tool_messages,\n",
    "    ]\n",
    "\n",
    "    final = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",  # Fixed model name\n",
    "        messages=followup_messages\n",
    "    )\n",
    "\n",
    "    return final.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d2edda",
   "metadata": {},
   "source": [
    "### Defining the Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5979769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "#  Define the TOOL functions (these run locally)\n",
    "# =====================================================\n",
    "\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('insurance_agent.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def ask_user(question: str, missing_info: str = \"\"):\n",
    "    \"\"\"Ask the user for input and return the response.\"\"\"\n",
    "    logger.info(f\"🗣️ Asking user for input: {question}\")\n",
    "    if missing_info:\n",
    "        print(f\"---USER INPUT REQUIRED---\\nMissing information: {missing_info}\")\n",
    "    else:\n",
    "        print(f\"---USER INPUT REQUIRED---\")\n",
    "    \n",
    "    answer = input(f\"{question}: \")\n",
    "    logger.info(f\"✅ User provided response: {answer}\")\n",
    "    return {\"context\": answer, \"source\": \"User Input\"}\n",
    "\n",
    "def get_policy_details(policy_number: str) -> Dict[str, Any]:\n",
    "    \"\"\"Fetch a customer's policy details by policy number\"\"\"\n",
    "    logger.info(f\"🔍 Fetching policy details for: {policy_number}\")\n",
    "    conn = sqlite3.connect('insurance_support.db')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT p.*, c.first_name, c.last_name \n",
    "        FROM policies p \n",
    "        JOIN customers c ON p.customer_id = c.customer_id \n",
    "        WHERE p.policy_number = ?\n",
    "    \"\"\", (policy_number,))\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "    if result:\n",
    "        logger.info(f\"✅ Policy found: {policy_number}\")\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        return dict(zip(columns, result))\n",
    "    logger.warning(f\"❌ Policy not found: {policy_number}\")\n",
    "    return {\"error\": \"Policy not found\"}\n",
    "\n",
    "def get_claim_status(claim_id: str = None, policy_number: str = None) -> Dict[str, Any]:\n",
    "    \"\"\"Get claim status and details\"\"\"\n",
    "    logger.info(f\"🔍 Fetching claim status - Claim ID: {claim_id}, Policy: {policy_number}\")\n",
    "    conn = sqlite3.connect('insurance_support.db')\n",
    "    cursor = conn.cursor()\n",
    "    if claim_id:\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT c.*, p.policy_type \n",
    "            FROM claims c\n",
    "            JOIN policies p ON c.policy_number = p.policy_number\n",
    "            WHERE c.claim_id = ?\n",
    "        \"\"\", (claim_id,))\n",
    "    elif policy_number:\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT c.*, p.policy_type \n",
    "            FROM claims c\n",
    "            JOIN policies p ON c.policy_number = p.policy_number\n",
    "            WHERE c.policy_number = ?\n",
    "            ORDER BY c.claim_date DESC LIMIT 3\n",
    "        \"\"\", (policy_number,))\n",
    "    result = cursor.fetchall()\n",
    "    conn.close()\n",
    "    if result:\n",
    "        logger.info(f\"✅ Found {len(result)} claim(s)\")\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        return [dict(zip(columns, row)) for row in result]\n",
    "    logger.warning(\"❌ No claims found\")\n",
    "    return {\"error\": \"Claim not found\"}\n",
    "\n",
    "def get_billing_info(policy_number: str = None, customer_id: str = None) -> Dict[str, Any]:\n",
    "    \"\"\"Get billing information including current balance and due dates\"\"\"\n",
    "    logger.info(f\"🔍 Fetching billing info - Policy: {policy_number}, Customer: {customer_id}\")\n",
    "    conn = sqlite3.connect('insurance_support.db')\n",
    "    cursor = conn.cursor()\n",
    "    if policy_number:\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT b.*, p.premium_amount, p.billing_frequency\n",
    "            FROM billing b\n",
    "            JOIN policies p ON b.policy_number = p.policy_number\n",
    "            WHERE b.policy_number = ? AND b.status = 'pending'\n",
    "            ORDER BY b.due_date DESC LIMIT 1\n",
    "        \"\"\", (policy_number,))\n",
    "    elif customer_id:\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT b.*, p.premium_amount, p.billing_frequency\n",
    "            FROM billing b\n",
    "            JOIN policies p ON b.policy_number = p.policy_number\n",
    "            WHERE p.customer_id = ? AND b.status = 'pending'\n",
    "            ORDER BY b.due_date DESC LIMIT 1\n",
    "        \"\"\", (customer_id,))\n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "    if result:\n",
    "        logger.info(\"✅ Billing info found\")\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        return dict(zip(columns, result))\n",
    "    logger.warning(\"❌ Billing info not found\")\n",
    "    return {\"error\": \"Billing information not found\"}\n",
    "\n",
    "def get_payment_history(policy_number: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Get payment history for a policy\"\"\"\n",
    "    logger.info(f\"🔍 Fetching payment history for policy: {policy_number}\")\n",
    "    conn = sqlite3.connect('insurance_support.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT p.payment_date, p.amount, p.status, p.payment_method\n",
    "        FROM payments p\n",
    "        JOIN billing b ON p.bill_id = b.bill_id\n",
    "        WHERE b.policy_number = ?\n",
    "        ORDER BY p.payment_date DESC LIMIT 10\n",
    "    \"\"\", (policy_number,))\n",
    "    \n",
    "    results = cursor.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    if results:\n",
    "        logger.info(f\"✅ Found {len(results)} payment records\")\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        return [dict(zip(columns, row)) for row in results]\n",
    "    logger.warning(\"❌ No payment history found\")\n",
    "    return []\n",
    "\n",
    "def get_auto_policy_details(policy_number: str) -> Dict[str, Any]:\n",
    "    \"\"\"Get auto-specific policy details including vehicle info and deductibles\"\"\"\n",
    "    logger.info(f\"🔍 Fetching auto policy details for: {policy_number}\")\n",
    "    conn = sqlite3.connect('insurance_support.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT apd.*, p.policy_type, p.premium_amount\n",
    "        FROM auto_policy_details apd\n",
    "        JOIN policies p ON apd.policy_number = p.policy_number\n",
    "        WHERE apd.policy_number = ?\n",
    "    \"\"\", (policy_number,))\n",
    "    \n",
    "    result = cursor.fetchone()\n",
    "    conn.close()\n",
    "    \n",
    "    if result:\n",
    "        logger.info(\"✅ Auto policy details found\")\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        return dict(zip(columns, result))\n",
    "    logger.warning(\"❌ Auto policy details not found\")\n",
    "    return {\"error\": \"Auto policy details not found\"}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246883d9",
   "metadata": {},
   "source": [
    "### Defining the Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a30f669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPERVISOR_PROMPT = \"\"\"\n",
    "You are the SUPERVISOR AGENT managing a team of insurance support specialists.\n",
    "\n",
    "Your role:\n",
    "1. Understand the user's intent and context.\n",
    "2. Evaluate available information and decide if clarification is needed.\n",
    "3. Route to the appropriate specialist agent.\n",
    "4. End conversation when the task is complete.\n",
    "\n",
    "AVAILABLE INFORMATION:\n",
    "- Policy Number: {policy_number}\n",
    "- Customer ID: {customer_id}\n",
    "- Context: {context_info}\n",
    "- Conversation History: {conversation_history}\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If policy number is already available, DO NOT ask for it again\n",
    "- If customer ID is already available, DO NOT ask for it again  \n",
    "- Only use ask_user tool if ESSENTIAL information is missing. Keep the clarification questions minimal (within 15 words) and specific.\n",
    "- Route directly to appropriate agent if you have sufficient information\n",
    "- Check the conversation history carefully - policy numbers or customer IDs mentioned earlier in the conversation should be considered available\n",
    "- If the user just provided information in response to your clarification question, that information is NOW available and should not be asked for again\n",
    "\n",
    "Specialist agents:\n",
    "- policy_agent → policy details, coverage, endorsements\n",
    "- billing_agent → billing, payments, premium questions\n",
    "- claims_agent → claim filing, tracking, settlements\n",
    "- human_escalation_agent → for complex cases\n",
    "- general_help_agent → for general questions\n",
    "\n",
    "CLARIFICICATION QUESTION GUIDELINES:\n",
    "1. Keep questions concise (<=15 words)\n",
    "2. Ask only for ESSENTIAL missing info (policy number, customer ID, claim ID)\n",
    "\n",
    "DECISION GUIDELINES:\n",
    "1. Policy/coverage questions → policy_agent\n",
    "2. Billing/payment questions → billing_agent  \n",
    "3. Claims questions → claims_agent\n",
    "4. General questions → general_help_agent\n",
    "5. Complete + answered → end\n",
    "\n",
    "TASK GENERATION GUIDELINES:\n",
    "1. If routing to a specialist, summarize the user's main request.\n",
    "2. Keep the policy number, customer ID, claim ID (if applicable and available) in Task also.\n",
    "\n",
    "Respond in JSON:\n",
    "{{\n",
    "  \"next_agent\": \"<agent_name or 'end'>\",\n",
    "  \"task\": \"<concise task description>\",\n",
    "  \"justification\": \"<why this decision>\"\n",
    "}}\n",
    "\n",
    "Only use ask_user tool if absolutely necessary.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "POLICY_AGENT_PROMPT = \"\"\"\n",
    "You are a **Policy Specialist Agent** for an insurance company.\n",
    "\n",
    "Assigned Task:\n",
    "{task}\n",
    "\n",
    "Responsibilities:\n",
    "1. Policy details, coverage, and deductibles\n",
    "2. Vehicle info and auto policy specifics\n",
    "3. Endorsements and policy updates\n",
    "\n",
    "Tools:\n",
    "- get_policy_details\n",
    "- get_auto_policy_details\n",
    "\n",
    "Context:\n",
    "- Policy Number: {policy_number}\n",
    "- Customer ID: {customer_id}\n",
    "- Conversation History: {conversation_history}\n",
    "\n",
    "Instructions:\n",
    "- Use tools to retrieve information as needed.\n",
    "- Ask politely for missing details.\n",
    "- Keep responses professional and clear.\n",
    "\"\"\"\n",
    "\n",
    "BILLING_AGENT_PROMPT = \"\"\"\n",
    "You are a **Billing Specialist Agent**.\n",
    "\n",
    "Assigned Task:\n",
    "{task}\n",
    "\n",
    "Responsibilities:\n",
    "1. Billing statements, payments, and invoices\n",
    "2. Premiums, due dates, and payment history\n",
    "\n",
    "Instructions:\n",
    "- Use tools to retrieve billing and payment information.\n",
    "- Ask politely for any missing details.\n",
    "- Just answer the questions that are asked. Don't provide extra information.\n",
    "- If you think the question is answered, don't ask for more information. Just retrun with the specific answer.\n",
    "\n",
    "Tools:\n",
    "- get_billing_info\n",
    "- get_payment_history\n",
    "\n",
    "Context:\n",
    "- Conversation History: {conversation_history}\n",
    "\"\"\"\n",
    "\n",
    "CLAIMS_AGENT_PROMPT = \"\"\"\n",
    "You are a **Claims Specialist Agent**.\n",
    "\n",
    "Assigned Task:\n",
    "{task}\n",
    "\n",
    "Responsibilities:\n",
    "1. Retrieve or update claim status\n",
    "2. Help file new claims\n",
    "3. Explain claim process and settlements\n",
    "\n",
    "Tools:\n",
    "- get_claim_status\n",
    "\n",
    "Context:\n",
    "- Policy Number: {policy_number}\n",
    "- Claim ID: {claim_id}\n",
    "- Conversation History: {conversation_history}\n",
    "\"\"\"\n",
    "\n",
    "GENERAL_HELP_PROMPT = \"\"\"\n",
    "You are a **General Help Agent** for insurance customers.\n",
    "\n",
    "Assigned Task:\n",
    "{task}\n",
    "\n",
    "Goal:\n",
    "Answer FAQs and explain insurance topics in simple, clear, and accurate language.\n",
    "\n",
    "Context:\n",
    "- Conversation History: {conversation_history}\n",
    "\n",
    "Retrieved FAQs from the knowledge base:\n",
    "{faq_context}\n",
    "\n",
    "Instructions:\n",
    "1. Review the retrieved FAQs carefully before answering.\n",
    "2. If one or more FAQs directly answer the question, use them to construct your response.\n",
    "3. If the FAQs are related but not exact, summarize the most relevant information.\n",
    "4. If no relevant FAQs are found, politely inform the user and provide general guidance.\n",
    "5. Keep responses clear, concise, and written for a non-technical audience.\n",
    "6. Do not fabricate details beyond what’s supported by the FAQs or obvious domain knowledge.\n",
    "7. End by offering further help (e.g., “Would you like to know more about this topic?”).\n",
    "\n",
    "Now provide the best possible answer for the user’s question.\n",
    "\"\"\"\n",
    "\n",
    "HUMAN_ESCALATION_PROMPT = \"\"\"\n",
    "You are handling a **Customer Escalation**.\n",
    "\n",
    "Assigned Task:\n",
    "{task}\n",
    "\n",
    "\n",
    "Conversation History: {conversation_history}\n",
    "\n",
    "Respond empathetically, acknowledge the request for a human, and confirm that a human representative will join shortly.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "FINAL_ANSWER_PROMPT = \"\"\"\n",
    "    The user asked: \"{user_query}\"\n",
    "    \n",
    "    The specialist agent provided this detailed response:\n",
    "    {specialist_response}\n",
    "    \n",
    "    Your task: Create a FINAL, CLEAN response that:\n",
    "    1. Directly answers the user's original question in a friendly tone\n",
    "    2. Includes only the most relevant information (remove technical details)\n",
    "    3. Is concise and easy to understand\n",
    "    4. Ends with a polite closing\n",
    "    \n",
    "    Important: Do NOT include any internal instructions, tool calls, or technical details.\n",
    "    Just provide the final answer that the user should see.\n",
    "    \n",
    "    Final response:\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e91e46",
   "metadata": {},
   "source": [
    "## Setting up the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59ae018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def supervisor_agent(state):\n",
    "    print(\"---SUPERVISOR AGENT---\")\n",
    "    logger.info(\"🔄 Supervisor agent started\")\n",
    "    \n",
    "    # Check if we're coming from a clarification\n",
    "    if state.get(\"needs_clarification\", False):\n",
    "        user_clarification = state.get(\"user_clarification\", \"\")\n",
    "        print(f\"🔄 Processing user clarification: {user_clarification}\")\n",
    "        logger.info(f\"🔄 Processing user clarification: {user_clarification}\")\n",
    "        \n",
    "        # Update conversation history with the clarification exchange\n",
    "        clarification_question = state.get(\"clarification_question\", \"\")\n",
    "        updated_conversation = state.get(\"conversation_history\", \"\") + f\"\\nAssistant: {clarification_question}\\nUser: {user_clarification}\"\n",
    "        \n",
    "        # Update state to clear clarification flags and update history\n",
    "        updated_state = state.copy()\n",
    "        updated_state[\"needs_clarification\"] = False\n",
    "        updated_state[\"conversation_history\"] = updated_conversation\n",
    "        \n",
    "        # Clear clarification fields\n",
    "        if \"clarification_question\" in updated_state:\n",
    "            del updated_state[\"clarification_question\"]\n",
    "        if \"user_clarification\" in updated_state:\n",
    "            del updated_state[\"user_clarification\"]\n",
    "            \n",
    "        return updated_state\n",
    "\n",
    "    user_query = state[\"user_input\"]\n",
    "    conversation_history = state.get(\"conversation_history\", \"\")\n",
    "    \n",
    "    # Check if we already have a policy number (including from previous iterations)\n",
    "    policy_number = state.get(\"policy_number\")\n",
    "    customer_id = state.get(\"customer_id\")\n",
    "    \n",
    "    print(f\"User Query: {user_query}\")\n",
    "    print(f\"Conversation History: {conversation_history}\")\n",
    "    if policy_number:\n",
    "        print(f\"✅ Available policy number: {policy_number}\")\n",
    "    if customer_id:\n",
    "        print(f\"✅ Available customer ID: {customer_id}\")\n",
    "    \n",
    "    logger.info(f\"📥 User query: {user_query}\")\n",
    "\n",
    "    # Build context for supervisor decision - include full conversation\n",
    "    context_info = \"\"\n",
    "    if policy_number:\n",
    "        context_info += f\"\\nAvailable Policy Number: {policy_number}\"\n",
    "    if customer_id:\n",
    "        context_info += f\"\\nAvailable Customer ID: {customer_id}\"\n",
    "    \n",
    "    # Include the ENTIRE conversation history in the prompt\n",
    "    full_context = f\"Full Conversation:\\n{conversation_history}\\n\\nCurrent Query: {user_query}\"\n",
    "    \n",
    "    prompt = SUPERVISOR_PROMPT.format(\n",
    "        #user_query=user_query,\n",
    "        conversation_history=full_context,  # Use full context instead of just history\n",
    "        context_info=context_info,\n",
    "        policy_number=policy_number or \"Not provided\",\n",
    "        customer_id=customer_id or \"Not provided\"\n",
    "    )\n",
    "\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"ask_user\",\n",
    "                \"description\": \"Ask the user for clarification or additional information when their query is unclear or missing important details. ONLY use this if essential information like policy number or customer ID is missing.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"question\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The specific question to ask the user for clarification\"\n",
    "                        },\n",
    "                        \"missing_info\": {\n",
    "                            \"type\": \"string\", \n",
    "                            \"description\": \"What specific information is missing or needs clarification\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"question\", \"missing_info\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    print(\"🤖 Calling LLM for supervisor decision...\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "\n",
    "    # Check if supervisor wants to ask user for clarification\n",
    "    if getattr(message, \"tool_calls\", None):\n",
    "        print(\"🛠️ Supervisor requesting user clarification\")\n",
    "        for tool_call in message.tool_calls:\n",
    "            if tool_call.function.name == \"ask_user\":\n",
    "                args = json.loads(tool_call.function.arguments)\n",
    "                question = args.get(\"question\", \"Can you please provide more details?\")\n",
    "                missing_info = args.get(\"missing_info\", \"additional information\")\n",
    "                \n",
    "                print(f\"❓ Asking user: {question}\")\n",
    "                logger.info(f\"❓ Asking user for clarification: {question}\")\n",
    "                \n",
    "                user_response_data = ask_user(question, missing_info)\n",
    "                user_response = user_response_data[\"context\"]\n",
    "                \n",
    "                print(f\"✅ User response: {user_response}\")\n",
    "                logger.info(f\"✅ User provided: {user_response}\")\n",
    "                \n",
    "                # Update conversation history with the question\n",
    "                updated_history = conversation_history + f\"\\nAssistant: {question}\"\n",
    "                updated_history = updated_history + f\"\\nUser: {user_response}\"\n",
    "                \n",
    "                return {\n",
    "                    \"needs_clarification\": True,\n",
    "                    \"clarification_question\": question,\n",
    "                    \"user_clarification\": user_response,\n",
    "                    \"conversation_history\": updated_history\n",
    "                }\n",
    "\n",
    "    # If no tool calls, proceed with normal supervisor decision\n",
    "    message_content = message.content\n",
    "    \n",
    "    try:\n",
    "        parsed = json.loads(message_content)\n",
    "        print(\"✅ Supervisor output parsed successfully\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"❌ Supervisor output invalid JSON, using fallback\")\n",
    "        parsed = {}\n",
    "\n",
    "    next_agent = parsed.get(\"next_agent\", \"general_help_agent\")\n",
    "    task = parsed.get(\"task\", \"Assist the user with their query.\")\n",
    "    justification = parsed.get(\"justification\", \"\")\n",
    "\n",
    "    print(f\"---SUPERVISOR DECISION: {next_agent}---\")\n",
    "    print(f\"Task: {task}\")\n",
    "    print(f\"Reason: {justification}\")\n",
    "    logger.info(f\"🎯 Supervisor Decision → {next_agent}\")\n",
    "\n",
    "    # Update conversation history with the current exchange\n",
    "    updated_conversation = conversation_history + f\"\\nUser: {user_query}\\nAssistant: Routing to {next_agent} for: {task}\"\n",
    "\n",
    "    # if next_agent == \"end\":\n",
    "    #     return {\n",
    "    #         \"next_agent\": \"final_answer_agent\",\n",
    "    #         \"task\": \"Generate a clean final summary of the response\",\n",
    "    #         \"justification\": \"Conversation complete - generating final summary for user\",\n",
    "    #         \"conversation_history\": updated_conversation\n",
    "    #     }\n",
    "\n",
    "    print(f\"➡️ Routing to: {next_agent}\")\n",
    "    return {\n",
    "        \"next_agent\": next_agent,\n",
    "        \"task\": task,\n",
    "        \"justification\": justification,\n",
    "        \"conversation_history\": updated_conversation\n",
    "    }\n",
    "\n",
    "def claims_agent_node(state):\n",
    "    logger.info(\"🏥 Claims agent started\")\n",
    "    logger.debug(f\"Claims agent state: { {k: v for k, v in state.items() if k != 'messages'} }\")\n",
    "    \n",
    "    prompt = CLAIMS_AGENT_PROMPT.format(\n",
    "        task=state.get(\"task\"),\n",
    "        #user_query=state.get(\"user_input\"),\n",
    "        policy_number=state.get(\"policy_number\", \"Not provided\"),\n",
    "        claim_id=state.get(\"claim_id\", \"Not provided\"),\n",
    "        conversation_history=state.get(\"conversation_history\", \"\")\n",
    "    )\n",
    "\n",
    "    tools = [\n",
    "        {\"type\": \"function\", \"function\": {\n",
    "            \"name\": \"get_claim_status\",\n",
    "            \"description\": \"Retrieve claim details\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {\"claim_id\": {\"type\": \"string\"}, \"policy_number\": {\"type\": \"string\"}}}\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "    result = run_llm_with_tools(prompt, tools, {\"get_claim_status\": get_claim_status})\n",
    "    \n",
    "    logger.info(\"✅ Claims agent completed\")\n",
    "    return {\"messages\": [(\"assistant\", result)]}\n",
    "\n",
    "def final_answer_agent(state):\n",
    "    \"\"\"Generate a clean final summary before ending the conversation\"\"\"\n",
    "    print(\"---FINAL ANSWER AGENT---\")\n",
    "    logger.info(\"🎯 Final answer agent started\")\n",
    "    \n",
    "    user_query = state[\"user_input\"]\n",
    "    conversation_history = state.get(\"conversation_history\", \"\")\n",
    "    \n",
    "    # Extract the most recent specialist response\n",
    "    recent_responses = []\n",
    "    for msg in reversed(state.get(\"messages\", [])):\n",
    "        if hasattr(msg, 'content') and \"clarification\" not in msg.content.lower():\n",
    "            recent_responses.append(msg.content)\n",
    "            if len(recent_responses) >= 2:  # Get last 2 non-clarification responses\n",
    "                break\n",
    "    \n",
    "    specialist_response = recent_responses[0] if recent_responses else \"No response available\"\n",
    "    \n",
    "    prompt = FINAL_ANSWER_PROMPT.format(\n",
    "        #user_query=user_query,\n",
    "        specialist_response=specialist_response,  \n",
    "        user_query=user_query,\n",
    "    )\n",
    "    \n",
    "    print(\"🤖 Generating final summary...\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    final_answer = response.choices[0].message.content\n",
    "    \n",
    "    print(f\"✅ Final answer: {final_answer}\")\n",
    "    logger.info(\"✅ Final answer generated\")\n",
    "    \n",
    "    # Replace all previous messages with just the final answer\n",
    "    clean_messages = [(\"assistant\", final_answer)]\n",
    "    \n",
    "    return {\n",
    "        \"messages\": clean_messages,\n",
    "        \"final_answer\": final_answer,\n",
    "        \"end_conversation\": True,\n",
    "        \"conversation_history\": conversation_history + f\"\\nAssistant: {final_answer}\"\n",
    "    }\n",
    "\n",
    "\n",
    "def run_llm_with_tools(prompt: str, tools: List[Dict], tool_functions: Dict[str, Any]):\n",
    "    print(f\"🤖 Calling LLM with {len(tools)} tools...\")\n",
    "    logger.info(f\"🤖 Calling LLM with {len(tools)} tools available\")\n",
    "    logger.debug(f\"Tools: {[tool['function']['name'] for tool in tools]}\")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",  # Changed from gpt-5-mini to actual model\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "    if not getattr(message, \"tool_calls\", None):\n",
    "        print(\"📝 LLM returned direct response\")\n",
    "        logger.info(\"📝 LLM returned direct response (no tool calls)\")\n",
    "        return message.content\n",
    "\n",
    "    print(f\"🛠️ LLM calling {len(message.tool_calls)} tool(s)\")\n",
    "    logger.info(f\"🛠️ LLM is calling {len(message.tool_calls)} tool(s)\")\n",
    "    \n",
    "    # Collect all tool responses\n",
    "    tool_responses = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        func_name = tool_call.function.name\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "        print(f\"🔧 Tool call: {func_name}\")\n",
    "        logger.info(f\"🔧 Tool call: {func_name} with args: {args}\")\n",
    "        \n",
    "        tool_fn = tool_functions.get(func_name)\n",
    "        if tool_fn:\n",
    "            print(f\"⚡ Executing: {func_name}\")\n",
    "            logger.info(f\"⚡ Executing tool: {func_name}\")\n",
    "            result = tool_fn(**args)\n",
    "            logger.debug(f\"Tool result: {result}\")\n",
    "            \n",
    "            # Add tool response to the list\n",
    "            tool_responses.append({\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": func_name,\n",
    "                \"content\": json.dumps(result)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"❌ Tool not found: {func_name}\")\n",
    "            logger.error(f\"❌ Tool function not found: {func_name}\")\n",
    "            result = {\"error\": f\"Tool {func_name} not available\"}\n",
    "            tool_responses.append({\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\", \n",
    "                \"name\": func_name,\n",
    "                \"content\": json.dumps(result)\n",
    "            })\n",
    "\n",
    "    print(\"🔄 Getting final response from LLM with tool results...\")\n",
    "    \n",
    "    # Build the messages for the final LLM call\n",
    "    final_messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": message.content,\n",
    "            \"tool_calls\": [\n",
    "                {\n",
    "                    \"id\": tool_call.id,\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tool_call.function.name,\n",
    "                        \"arguments\": tool_call.function.arguments\n",
    "                    }\n",
    "                }\n",
    "                for tool_call in message.tool_calls\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Add all tool responses\n",
    "    final_messages.extend(tool_responses)\n",
    "    \n",
    "    final_response = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=final_messages\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Tool execution completed\")\n",
    "    logger.info(\"✅ Tool execution completed, returning final response\")\n",
    "    return final_response.choices[0].message.content\n",
    "    \n",
    "\n",
    "def policy_agent_node(state):\n",
    "    print(\"---POLICY AGENT---\")\n",
    "    logger.info(\"📄 Policy agent started\")\n",
    "    logger.debug(f\"Policy agent state: { {k: v for k, v in state.items() if k != 'messages'} }\")\n",
    "    \n",
    "    prompt = POLICY_AGENT_PROMPT.format(\n",
    "        task=state.get(\"task\"),\n",
    "        #user_query=state.get(\"user_input\"),\n",
    "        policy_number=state.get(\"policy_number\", \"Not provided\"),\n",
    "        customer_id=state.get(\"customer_id\", \"Not provided\"),\n",
    "        conversation_history=state.get(\"conversation_history\", \"\")\n",
    "    )\n",
    "\n",
    "    tools = [\n",
    "        {\"type\": \"function\", \"function\": {\n",
    "            \"name\": \"get_policy_details\",\n",
    "            \"description\": \"Fetch policy info by policy number\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {\"policy_number\": {\"type\": \"string\"}}}\n",
    "        }},\n",
    "        {\"type\": \"function\", \"function\": {\n",
    "            \"name\": \"get_auto_policy_details\",\n",
    "            \"description\": \"Get auto policy details\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {\"policy_number\": {\"type\": \"string\"}}}\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "    print(\"🔄 Processing policy request...\")\n",
    "    result = run_llm_with_tools(prompt, tools, {\n",
    "        \"get_policy_details\": get_policy_details,\n",
    "        \"get_auto_policy_details\": get_auto_policy_details\n",
    "    })\n",
    "    \n",
    "    print(\"✅ Policy agent completed\")\n",
    "    logger.info(\"✅ Policy agent completed\")\n",
    "    return {\"messages\": [(\"assistant\", result)]}\n",
    "\n",
    "\n",
    "def billing_agent_node(state):\n",
    "    print(\"---BILLING AGENT---\")\n",
    "    logger.info(\"💰 Billing agent started\")\n",
    "    print(\"TASK: \", state.get(\"task\"))\n",
    "    print(\"USER QUERY: \", state.get(\"user_input\"))\n",
    "    print(\"CONVERSATION HISTORY: \", state.get(\"conversation_history\", \"\"))\n",
    "    \n",
    "    \n",
    "    prompt = BILLING_AGENT_PROMPT.format(\n",
    "        task=state.get(\"task\"),\n",
    "        #user_query=state.get(\"user_input\"),\n",
    "        #policy_number=state.get(\"policy_number\", \"Not provided\"),\n",
    "        #customer_id=state.get(\"customer_id\", \"Not provided\"),\n",
    "        conversation_history=state.get(\"conversation_history\", \"\")\n",
    "    )\n",
    "\n",
    "    tools = [\n",
    "        {\"type\": \"function\", \"function\": {\n",
    "            \"name\": \"get_billing_info\",\n",
    "            \"description\": \"Retrieve billing information\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {\"policy_number\": {\"type\": \"string\"}, \"customer_id\": {\"type\": \"string\"}}}\n",
    "        }},\n",
    "        {\"type\": \"function\", \"function\": {\n",
    "            \"name\": \"get_payment_history\",\n",
    "            \"description\": \"Fetch recent payment history\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {\"policy_number\": {\"type\": \"string\"}}}\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "    print(\"🔄 Processing billing request...\")\n",
    "    result = run_llm_with_tools(prompt, tools, {\n",
    "        \"get_billing_info\": get_billing_info,\n",
    "        \"get_payment_history\": get_payment_history\n",
    "    })\n",
    "    \n",
    "    print(\"✅ Billing agent completed\")\n",
    "    logger.info(\"✅ Billing agent completed\")\n",
    "    \n",
    "    # Extract and preserve policy number if mentioned in the conversation\n",
    "    updated_state = {\"messages\": [(\"assistant\", result)]}\n",
    "    \n",
    "    # If we have a policy number in state, preserve it\n",
    "    if state.get(\"policy_number\"):\n",
    "        updated_state[\"policy_number\"] = state[\"policy_number\"]\n",
    "    if state.get(\"customer_id\"):\n",
    "        updated_state[\"customer_id\"] = state[\"customer_id\"]\n",
    "        \n",
    "    # Update conversation history\n",
    "    current_history = state.get(\"conversation_history\", \"\")\n",
    "    updated_state[\"conversation_history\"] = current_history + f\"\\nBilling Agent: {result}\"\n",
    "    \n",
    "    return updated_state\n",
    "\n",
    "\n",
    "\n",
    "def general_help_agent_node(state):\n",
    "    print(\"---GENERAL HELP AGENT---\")\n",
    "    logger.info(\"ℹ️ General help agent started\")\n",
    "    logger.debug(f\"General help state: { {k: v for k, v in state.items() if k != 'messages'} }\")\n",
    "    \n",
    "    user_query = state.get(\"user_input\", \"\")\n",
    "    conversation_history = state.get(\"conversation_history\", \"\")\n",
    "    task = state.get(\"task\", \"General insurance support\")\n",
    "\n",
    "    # Step 1: Retrieve relevant FAQs from the vector DB\n",
    "    print(\"🔍 Retrieving FAQs...\")\n",
    "    logger.info(\"🔍 Retrieving FAQs from vector database\")\n",
    "    results = collection.query(\n",
    "        query_texts=[user_query],\n",
    "        n_results=3,\n",
    "        include=[\"metadatas\", \"documents\", \"distances\"]\n",
    "    )\n",
    "\n",
    "    # Step 2: Format retrieved FAQs\n",
    "    faq_context = \"\"\n",
    "    if results and results.get(\"metadatas\") and results[\"metadatas\"][0]:\n",
    "        print(f\"📚 Found {len(results['metadatas'][0])} relevant FAQs\")\n",
    "        logger.info(f\"📚 Found {len(results['metadatas'][0])} relevant FAQs\")\n",
    "        for i, meta in enumerate(results[\"metadatas\"][0]):\n",
    "            q = meta.get(\"question\", \"\")\n",
    "            a = meta.get(\"answer\", \"\")\n",
    "            score = results[\"distances\"][0][i]\n",
    "            faq_context += f\"FAQ {i+1} (score: {score:.3f})\\nQ: {q}\\nA: {a}\\n\\n\"\n",
    "    else:\n",
    "        print(\"❌ No relevant FAQs found\")\n",
    "        logger.info(\"❌ No relevant FAQs found\")\n",
    "        faq_context = \"No relevant FAQs were found.\"\n",
    "\n",
    "    # Step 3: Format the final prompt\n",
    "    prompt = GENERAL_HELP_PROMPT.format(\n",
    "        task=task,\n",
    "        #user_query=user_query,\n",
    "        conversation_history=conversation_history,\n",
    "        faq_context=faq_context\n",
    "    )\n",
    "\n",
    "    print(\"🤖 Generating response...\")\n",
    "    logger.info(\"🤖 Calling LLM for general help response\")\n",
    "    final_answer = llm_without_tool(prompt)\n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"✅ General help agent completed\")\n",
    "    logger.info(\"✅ General help agent completed\")\n",
    "    updated_state = {\n",
    "                        \"messages\": [(\"assistant\", final_answer)],\n",
    "                        \"retrieved_faqs\": results.get(\"metadatas\", []),\n",
    "                    }\n",
    "\n",
    "\n",
    "    updated_state[\"conversation_history\"] = conversation_history + f\"\\nGeneral Help Agent: {final_answer}\"\n",
    "\n",
    "    return updated_state\n",
    "\n",
    "\n",
    "def human_escalation_node(state):\n",
    "    print(\"---HUMAN ESCALATION AGENT---\")\n",
    "    logger.info(\"👨‍💼 Human escalation agent started\")\n",
    "    logger.warning(f\"Escalation triggered - State: { {k: v for k, v in state.items() if k != 'messages'} }\")\n",
    "    \n",
    "    prompt = HUMAN_ESCALATION_PROMPT.format(\n",
    "        task=state.get(\"task\"),\n",
    "        #user_query=state.get(\"user_input\"),\n",
    "        conversation_history=state.get(\"conversation_history\", \"\")\n",
    "    )\n",
    "\n",
    "    print(\"🤖 Generating escalation response...\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    print(\"🚨 Conversation escalated to human\")\n",
    "    logger.info(\"🚨 Conversation escalated to human agent\")\n",
    "    return {\n",
    "        \"requires_human_escalation\": True,\n",
    "        \"escalation_reason\": \"Customer requested human assistance.\",\n",
    "        \"messages\": [(\"assistant\", response.choices[0].message.content)]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "from typing import TypedDict, List, Annotated, Dict, Any, Optional\n",
    "from langgraph.graph import add_messages\n",
    "from datetime import datetime\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    # Core conversation tracking\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    user_input: str\n",
    "    conversation_history: Optional[str]\n",
    "\n",
    "    # Extracted context & metadata\n",
    "    user_intent: Optional[str]            # e.g., \"query_policy\", \"billing_issue\"\n",
    "    customer_id: Optional[str]\n",
    "    policy_number: Optional[str]\n",
    "    claim_id: Optional[str]\n",
    "    \n",
    "    # Supervisor / routing layer\n",
    "    next_agent: Optional[str]             # e.g., \"policy_agent\", \"claims_agent\", etc.\n",
    "    task: Optional[str]                   # Current task determined by supervisor\n",
    "    justification: Optional[str]          # Supervisor reasoning/explanation\n",
    "    end_conversation: Optional[bool]      # Flag for graceful conversation termination\n",
    "    \n",
    "    # Entity extraction and DB lookups\n",
    "    extracted_entities: Dict[str, Any]    # Parsed from user input (dates, names, etc.)\n",
    "    database_lookup_result: Dict[str, Any]\n",
    "    \n",
    "    # Escalation state\n",
    "    requires_human_escalation: bool\n",
    "    escalation_reason: Optional[str]\n",
    "    \n",
    "    # Billing-specific fields\n",
    "    billing_amount: Optional[float]\n",
    "    payment_method: Optional[str]\n",
    "    billing_frequency: Optional[str]      # \"monthly\", \"quarterly\", \"annual\"\n",
    "    invoice_date: Optional[str]\n",
    "    \n",
    "    # System-level metadata\n",
    "    timestamp: Optional[str]              # Track time of latest user message or state update\n",
    "\n",
    "\n",
    "def decide_next_agent(state):\n",
    "    # Handle clarification case first\n",
    "    if state.get(\"needs_clarification\"):\n",
    "        return \"supervisor_agent\"  # Return to supervisor to process the clarification\n",
    "    \n",
    "    if state.get(\"end_conversation\"):\n",
    "        return \"end\"\n",
    "    \n",
    "    if state.get(\"requires_human_escalation\"):\n",
    "        return \"human_escalation_agent\"\n",
    "    \n",
    "    return state.get(\"next_agent\", \"general_help_agent\")\n",
    "\n",
    "# Update the workflow to include the final_answer_agent\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"supervisor_agent\", supervisor_agent)\n",
    "workflow.add_node(\"policy_agent\", policy_agent_node)\n",
    "workflow.add_node(\"billing_agent\", billing_agent_node)\n",
    "workflow.add_node(\"claims_agent\", claims_agent_node)\n",
    "workflow.add_node(\"general_help_agent\", general_help_agent_node)\n",
    "workflow.add_node(\"human_escalation_agent\", human_escalation_node)\n",
    "workflow.add_node(\"final_answer_agent\", final_answer_agent)  # Add this\n",
    "\n",
    "workflow.set_entry_point(\"supervisor_agent\")\n",
    "\n",
    "def decide_next_agent(state):\n",
    "    # Handle clarification case first\n",
    "    if state.get(\"needs_clarification\"):\n",
    "        return \"supervisor_agent\"\n",
    "    \n",
    "    if state.get(\"end_conversation\"):\n",
    "        return \"end\"\n",
    "    \n",
    "    if state.get(\"requires_human_escalation\"):\n",
    "        return \"human_escalation_agent\"\n",
    "    \n",
    "    return state.get(\"next_agent\", \"general_help_agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor_agent\",\n",
    "    decide_next_agent,\n",
    "    {\n",
    "        \"policy_agent\": \"policy_agent\",\n",
    "        \"billing_agent\": \"billing_agent\", \n",
    "        \"claims_agent\": \"claims_agent\",\n",
    "        \"human_escalation_agent\": \"human_escalation_agent\",\n",
    "        \"general_help_agent\": \"general_help_agent\",\n",
    "        #\"final_answer_agent\": \"final_answer_agent\",  # Add this\n",
    "        \"end\": \"final_answer_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Return to Supervisor after each specialist\n",
    "for node in [\"policy_agent\", \"billing_agent\", \"claims_agent\", \"general_help_agent\"]:\n",
    "    workflow.add_edge(node, \"supervisor_agent\")\n",
    "\n",
    "# Final answer agent → END\n",
    "workflow.add_edge(\"final_answer_agent\", END)\n",
    "\n",
    "# Human escalation → END\n",
    "workflow.add_edge(\"human_escalation_agent\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "# === Display the Graph ===\n",
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c41a30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_test_query(query):\n",
    "    \"\"\"Test the system with a billing query\"\"\"\n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"user_input\": query,\n",
    "        \"user_intent\": \"\",\n",
    "        \"claim_id\": \"\",\n",
    "        \"next_agent\": \"supervisor_agent\",\n",
    "        \"extracted_entities\": {},\n",
    "        \"database_lookup_result\": {},\n",
    "        \"requires_human_escalation\": False,\n",
    "        \"escalation_reason\": \"\",\n",
    "        \"billing_amount\": None,\n",
    "        \"payment_method\": None,\n",
    "        \"billing_frequency\": None,\n",
    "        \"invoice_date\": None,\n",
    "        \"conversation_history\": f\"User: {query}\", \n",
    "        \"task\": \"Help user with their query\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    \n",
    "    # Run the graph\n",
    "    final_state = app.invoke(initial_state)\n",
    "    \n",
    "    # Print the response\n",
    "    print(\"\\n---FINAL RESPONSE---\")\n",
    "    assistant_messages = []\n",
    "    \n",
    "    # Extract all assistant messages from different message formats\n",
    "    for message in final_state.get(\"messages\", []):\n",
    "        if isinstance(message, tuple) and message[0] == \"assistant\":\n",
    "            assistant_messages.append(message[1])\n",
    "            print(f\"ASSISTANT: {message[1]}\")\n",
    "        elif isinstance(message, dict) and message.get(\"role\") == \"assistant\":\n",
    "            content = message.get('content', '')\n",
    "            assistant_messages.append(content)\n",
    "            print(f\"ASSISTANT: {content}\")\n",
    "        elif hasattr(message, 'content'):  # Handle AIMessage objects\n",
    "            assistant_messages.append(message.content)\n",
    "            print(f\"ASSISTANT: {message.content}\")\n",
    "        elif isinstance(message, str):\n",
    "            assistant_messages.append(message)\n",
    "            print(f\"ASSISTANT: {message}\")\n",
    "    \n",
    "    # If no assistant messages found, check conversation history\n",
    "    if not assistant_messages:\n",
    "        print(\"No assistant messages found in final state.\")\n",
    "        if \"conversation_history\" in final_state:\n",
    "            print(f\"CONVERSATION HISTORY: {final_state['conversation_history']}\")\n",
    "    \n",
    "    return final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:17:07,065 - __main__ - INFO - 🔄 Supervisor agent started\n",
      "2025-11-10 19:17:07,066 - __main__ - INFO - 📥 User query: What is the premium of my auto insurance policy?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "QUERY: What is the premium of my auto insurance policy?\n",
      "\n",
      "==================================================\n",
      "---SUPERVISOR AGENT---\n",
      "User Query: What is the premium of my auto insurance policy?\n",
      "Conversation History: User: What is the premium of my auto insurance policy?\n",
      "🤖 Calling LLM for supervisor decision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:17:08,614 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 19:17:08,773 - __main__ - INFO - ❓ Asking user for clarification: Please provide your policy number.\n",
      "2025-11-10 19:17:08,776 - __main__ - INFO - 🗣️ Asking user for input: Please provide your policy number.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Supervisor requesting user clarification\n",
      "❓ Asking user: Please provide your policy number.\n",
      "---USER INPUT REQUIRED---\n",
      "Missing information: policy number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:17:13,288 - __main__ - INFO - ✅ User provided response: POL000001\n",
      "2025-11-10 19:17:13,289 - __main__ - INFO - ✅ User provided: POL000001\n",
      "2025-11-10 19:17:13,293 - __main__ - INFO - 🔄 Supervisor agent started\n",
      "2025-11-10 19:17:13,294 - __main__ - INFO - 📥 User query: What is the premium of my auto insurance policy?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ User response: POL000001\n",
      "---SUPERVISOR AGENT---\n",
      "User Query: What is the premium of my auto insurance policy?\n",
      "Conversation History: User: What is the premium of my auto insurance policy?\n",
      "Assistant: Please provide your policy number.\n",
      "User: POL000001\n",
      "🤖 Calling LLM for supervisor decision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:17:14,907 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 19:17:14,916 - __main__ - INFO - 🎯 Supervisor Decision → billing_agent\n",
      "2025-11-10 19:17:14,918 - __main__ - INFO - 💰 Billing agent started\n",
      "2025-11-10 19:17:14,919 - __main__ - INFO - 🤖 Calling LLM with 2 tools available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor output parsed successfully\n",
      "---SUPERVISOR DECISION: billing_agent---\n",
      "Task: Check the premium for auto insurance policy POL000001.\n",
      "Reason: The user provided the policy number and is inquiring about the premium, which is a billing question.\n",
      "➡️ Routing to: billing_agent\n",
      "---BILLING AGENT---\n",
      "TASK:  Check the premium for auto insurance policy POL000001.\n",
      "USER QUERY:  What is the premium of my auto insurance policy?\n",
      "CONVERSATION HISTORY:  User: What is the premium of my auto insurance policy?\n",
      "Assistant: Please provide your policy number.\n",
      "User: POL000001\n",
      "User: What is the premium of my auto insurance policy?\n",
      "Assistant: Routing to billing_agent for: Check the premium for auto insurance policy POL000001.\n",
      "🔄 Processing billing request...\n",
      "🤖 Calling LLM with 2 tools...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:17:19,656 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 19:17:19,667 - __main__ - INFO - 🛠️ LLM is calling 2 tool(s)\n",
      "2025-11-10 19:17:19,668 - __main__ - INFO - 🔧 Tool call: get_billing_info with args: {'policy_number': 'POL000001'}\n",
      "2025-11-10 19:17:19,668 - __main__ - INFO - ⚡ Executing tool: get_billing_info\n",
      "2025-11-10 19:17:19,669 - __main__ - INFO - 🔍 Fetching billing info - Policy: POL000001, Customer: None\n",
      "2025-11-10 19:17:19,673 - __main__ - INFO - ✅ Billing info found\n",
      "2025-11-10 19:17:19,674 - __main__ - INFO - 🔧 Tool call: get_payment_history with args: {'policy_number': 'POL000001'}\n",
      "2025-11-10 19:17:19,674 - __main__ - INFO - ⚡ Executing tool: get_payment_history\n",
      "2025-11-10 19:17:19,674 - __main__ - INFO - 🔍 Fetching payment history for policy: POL000001\n",
      "2025-11-10 19:17:19,681 - __main__ - INFO - ✅ Found 5 payment records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ LLM calling 2 tool(s)\n",
      "🔧 Tool call: get_billing_info\n",
      "⚡ Executing: get_billing_info\n",
      "🔧 Tool call: get_payment_history\n",
      "⚡ Executing: get_payment_history\n",
      "🔄 Getting final response from LLM with tool results...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:17:26,735 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 19:17:26,740 - __main__ - INFO - ✅ Tool execution completed, returning final response\n",
      "2025-11-10 19:17:26,742 - __main__ - INFO - ✅ Billing agent completed\n",
      "2025-11-10 19:17:26,748 - __main__ - INFO - 🔄 Supervisor agent started\n",
      "2025-11-10 19:17:26,749 - __main__ - INFO - 📥 User query: What is the premium of my auto insurance policy?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tool execution completed\n",
      "✅ Billing agent completed\n",
      "---SUPERVISOR AGENT---\n",
      "User Query: What is the premium of my auto insurance policy?\n",
      "Conversation History: User: What is the premium of my auto insurance policy?\n",
      "Assistant: Please provide your policy number.\n",
      "User: POL000001\n",
      "User: What is the premium of my auto insurance policy?\n",
      "Assistant: Routing to billing_agent for: Check the premium for auto insurance policy POL000001.\n",
      "Billing Agent: The premium for policy POL000001 is $202.11 per quarter.\n",
      "🤖 Calling LLM for supervisor decision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:17:29,479 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 19:17:29,489 - __main__ - INFO - 🎯 Supervisor Decision → end\n",
      "2025-11-10 19:17:29,491 - __main__ - INFO - 🎯 Final answer agent started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor output parsed successfully\n",
      "---SUPERVISOR DECISION: end---\n",
      "Task: The premium for policy POL000001 is $202.11 per quarter.\n",
      "Reason: The premium information has already been provided by the billing agent.\n",
      "---FINAL ANSWER AGENT---\n",
      "🤖 Generating final summary...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:17:36,650 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 19:17:36,664 - __main__ - INFO - ✅ Final answer generated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final answer: Your auto insurance premium is $202.11 per quarter. Thank you.\n",
      "\n",
      "---FINAL RESPONSE---\n",
      "ASSISTANT: The premium for policy POL000001 is $202.11 per quarter.\n",
      "ASSISTANT: Your auto insurance premium is $202.11 per quarter. Thank you.\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the premium of my auto insurance policy?\"\n",
    "final_output =     run_test_query(test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0403c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:36:05,839 - __main__ - INFO - 🔄 Supervisor agent started\n",
      "2025-11-10 19:36:05,841 - __main__ - INFO - 📥 User query: In general, what does life insurance cover? Route this to the general help agent.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "QUERY: In general, what does life insurance cover? Route this to the general help agent.\n",
      "\n",
      "==================================================\n",
      "---SUPERVISOR AGENT---\n",
      "User Query: In general, what does life insurance cover? Route this to the general help agent.\n",
      "Conversation History: User: In general, what does life insurance cover? Route this to the general help agent.\n",
      "🤖 Calling LLM for supervisor decision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:36:07,802 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 19:36:07,806 - __main__ - INFO - 🎯 Supervisor Decision → general_help_agent\n",
      "2025-11-10 19:36:07,808 - __main__ - INFO - ℹ️ General help agent started\n",
      "2025-11-10 19:36:07,809 - __main__ - INFO - 🔍 Retrieving FAQs from vector database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor output parsed successfully\n",
      "---SUPERVISOR DECISION: general_help_agent---\n",
      "Task: User inquired about what life insurance covers.\n",
      "Reason: The user asked a general question about life insurance coverage.\n",
      "➡️ Routing to: general_help_agent\n",
      "---GENERAL HELP AGENT---\n",
      "🔍 Retrieving FAQs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:36:08,017 - __main__ - INFO - 📚 Found 3 relevant FAQs\n",
      "2025-11-10 19:36:08,018 - __main__ - INFO - 🤖 Calling LLM for general help response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Found 3 relevant FAQs\n",
      "🤖 Generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:36:16,265 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 19:36:16,271 - __main__ - INFO - ✅ General help agent completed\n",
      "2025-11-10 19:36:16,273 - __main__ - INFO - 🔄 Supervisor agent started\n",
      "2025-11-10 19:36:16,274 - __main__ - INFO - 📥 User query: In general, what does life insurance cover? Route this to the general help agent.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ General help agent completed\n",
      "---SUPERVISOR AGENT---\n",
      "User Query: In general, what does life insurance cover? Route this to the general help agent.\n",
      "Conversation History: User: In general, what does life insurance cover? Route this to the general help agent.\n",
      "User: In general, what does life insurance cover? Route this to the general help agent.\n",
      "Assistant: Routing to general_help_agent for: User inquired about what life insurance covers.\n",
      "General Help Agent: In general, life insurance pays a death benefit to the person(s) you name (the beneficiaries) if the insured person dies while the policy is in force.\n",
      "\n",
      "Typical points to know:\n",
      "- What it pays for: the payout is intended to help your family or other beneficiaries with things like paying off debt, covering living expenses or college costs, and paying funeral or other final expenses.\n",
      "- What causes of death are covered: most policies cover death from illness, injury, or “old age.” Many policies also pay after the policy has been in force for a certain time even if the death was by suicide.\n",
      "- Who controls the money: the policy owner controls the policy (including who the beneficiaries are), so the owner can change beneficiaries unless contract terms say otherwise.\n",
      "\n",
      "Policy details, limits, exclusions, and timing (for example, contestability or suicide clauses) can vary, so check your policy or talk with a local agent for specifics. Would you like help with types of life insurance or how to choose a beneficiary?\n",
      "🤖 Calling LLM for supervisor decision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:36:18,127 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 19:36:18,130 - __main__ - INFO - 🎯 Supervisor Decision → general_help_agent\n",
      "2025-11-10 19:36:18,132 - __main__ - INFO - ℹ️ General help agent started\n",
      "2025-11-10 19:36:18,139 - __main__ - INFO - 🔍 Retrieving FAQs from vector database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor output parsed successfully\n",
      "---SUPERVISOR DECISION: general_help_agent---\n",
      "Task: User inquired about what life insurance covers.\n",
      "Reason: User's query is a general question about life insurance coverage.\n",
      "➡️ Routing to: general_help_agent\n",
      "---GENERAL HELP AGENT---\n",
      "🔍 Retrieving FAQs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:36:18,590 - __main__ - INFO - 📚 Found 3 relevant FAQs\n",
      "2025-11-10 19:36:18,590 - __main__ - INFO - 🤖 Calling LLM for general help response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Found 3 relevant FAQs\n",
      "🤖 Generating response...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:36:28,313 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 19:36:28,323 - __main__ - INFO - ✅ General help agent completed\n",
      "2025-11-10 19:36:28,328 - __main__ - INFO - 🔄 Supervisor agent started\n",
      "2025-11-10 19:36:28,329 - __main__ - INFO - 📥 User query: In general, what does life insurance cover? Route this to the general help agent.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ General help agent completed\n",
      "---SUPERVISOR AGENT---\n",
      "User Query: In general, what does life insurance cover? Route this to the general help agent.\n",
      "Conversation History: User: In general, what does life insurance cover? Route this to the general help agent.\n",
      "User: In general, what does life insurance cover? Route this to the general help agent.\n",
      "Assistant: Routing to general_help_agent for: User inquired about what life insurance covers.\n",
      "General Help Agent: In general, life insurance pays a death benefit to the person(s) you name (the beneficiaries) if the insured person dies while the policy is in force.\n",
      "\n",
      "Typical points to know:\n",
      "- What it pays for: the payout is intended to help your family or other beneficiaries with things like paying off debt, covering living expenses or college costs, and paying funeral or other final expenses.\n",
      "- What causes of death are covered: most policies cover death from illness, injury, or “old age.” Many policies also pay after the policy has been in force for a certain time even if the death was by suicide.\n",
      "- Who controls the money: the policy owner controls the policy (including who the beneficiaries are), so the owner can change beneficiaries unless contract terms say otherwise.\n",
      "\n",
      "Policy details, limits, exclusions, and timing (for example, contestability or suicide clauses) can vary, so check your policy or talk with a local agent for specifics. Would you like help with types of life insurance or how to choose a beneficiary?\n",
      "User: In general, what does life insurance cover? Route this to the general help agent.\n",
      "Assistant: Routing to general_help_agent for: User inquired about what life insurance covers.\n",
      "General Help Agent: In general, life insurance pays a cash benefit to the person(s) you name (your beneficiaries) if the insured person dies while the policy is active. Here are the key points in simple terms:\n",
      "\n",
      "- What it pays for\n",
      "  - The death benefit is meant to help your family or other beneficiaries with expenses such as paying off debts, replacing lost income, covering living costs or college, and paying funeral or other final expenses.\n",
      "\n",
      "- What causes of death are covered\n",
      "  - Most policies pay if the insured dies from illness, injury, or “old age.” Many policies will also pay after they’ve been active for a certain period even if the death was by suicide.\n",
      "\n",
      "- Who controls the money\n",
      "  - The policy owner controls the policy (including who the beneficiaries are). That means the owner can usually change beneficiaries unless the contract says otherwise.\n",
      "\n",
      "- Important to check\n",
      "  - Exact coverage, limits, exclusions, and timing (for example, any waiting or contestability periods) vary by policy and insurer. Check your policy documents or talk with a local agent for specifics.\n",
      "\n",
      "Would you like help comparing types of life insurance (term vs. permanent) or tips on choosing a beneficiary?\n",
      "🤖 Calling LLM for supervisor decision...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:36:30,020 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-10 19:36:30,026 - __main__ - INFO - 🎯 Supervisor Decision → general_help_agent\n",
      "2025-11-10 19:36:30,028 - __main__ - INFO - ℹ️ General help agent started\n",
      "2025-11-10 19:36:30,029 - __main__ - INFO - 🔍 Retrieving FAQs from vector database\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Supervisor output parsed successfully\n",
      "---SUPERVISOR DECISION: general_help_agent---\n",
      "Task: User inquired again about what life insurance covers.\n",
      "Reason: User is repeatedly asking about the coverage details of life insurance.\n",
      "➡️ Routing to: general_help_agent\n",
      "---GENERAL HELP AGENT---\n",
      "🔍 Retrieving FAQs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 19:36:30,242 - __main__ - INFO - 📚 Found 3 relevant FAQs\n",
      "2025-11-10 19:36:30,243 - __main__ - INFO - 🤖 Calling LLM for general help response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Found 3 relevant FAQs\n",
      "🤖 Generating response...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m test_query = \u001b[33m\"\u001b[39m\u001b[33mIn general, what does life insurance cover? Route this to the general help agent.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m final_output =     \u001b[43mrun_test_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_query\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mrun_test_query\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Run the graph\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m final_state = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Print the response\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m---FINAL RESPONSE---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:3094\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3091\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3092\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3094\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3100\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3102\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3104\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3106\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3107\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3108\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3109\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:2679\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2677\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2678\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2679\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2689\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 470\u001b[39m, in \u001b[36mgeneral_help_agent_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🤖 Generating response...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    469\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33m🤖 Calling LLM for general help response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m470\u001b[39m final_answer = \u001b[43mllm_without_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ General help agent completed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    475\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33m✅ General help agent completed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mllm_without_tool\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      7\u001b[39m client_llm = OpenAI(api_key=openai_api_key)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[43mclient_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-5-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:1156\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1110\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1112\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1153\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1154\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1155\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/multi-agent-system/.venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1285\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1284\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1140\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "test_query = \"In general, what does life insurance cover? Route this to the general help agent.\"\n",
    "final_output =     run_test_query(test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e120f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='The premium for policy POL000001 is $202.11 per quarter.', additional_kwargs={}, response_metadata={}, id='a0240514-d51c-4652-a26a-c62509b11b2e'),\n",
       "  AIMessage(content='Your auto insurance premium is $202.11 per quarter. Thank you.', additional_kwargs={}, response_metadata={}, id='d4346144-d4f8-4862-9e3f-b957e3dba6e2')],\n",
       " 'user_input': 'What is the premium of my auto insurance policy?',\n",
       " 'conversation_history': 'User: What is the premium of my auto insurance policy?\\nAssistant: Please provide your policy number.\\nUser: POL000001\\nUser: What is the premium of my auto insurance policy?\\nAssistant: Routing to billing_agent for: Check the premium for auto insurance policy POL000001.\\nBilling Agent: The premium for policy POL000001 is $202.11 per quarter.\\nUser: What is the premium of my auto insurance policy?\\nAssistant: Routing to end for: The premium for policy POL000001 is $202.11 per quarter.\\nAssistant: Your auto insurance premium is $202.11 per quarter. Thank you.',\n",
       " 'user_intent': '',\n",
       " 'claim_id': '',\n",
       " 'next_agent': 'final_answer_agent',\n",
       " 'task': 'Generate a clean final summary of the response',\n",
       " 'justification': 'Conversation complete - generating final summary for user',\n",
       " 'end_conversation': True,\n",
       " 'extracted_entities': {},\n",
       " 'database_lookup_result': {},\n",
       " 'requires_human_escalation': False,\n",
       " 'escalation_reason': '',\n",
       " 'billing_amount': None,\n",
       " 'payment_method': None,\n",
       " 'billing_frequency': None,\n",
       " 'invoice_date': None}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d3886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
